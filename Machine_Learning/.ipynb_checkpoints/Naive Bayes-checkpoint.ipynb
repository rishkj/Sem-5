{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy during testing of fold  1  is : 0.6873\n",
      "Accuracy during testing of fold  2  is : 0.6827\n",
      "Accuracy during testing of fold  3  is : 0.6981\n",
      "Accuracy during testing of fold  4  is : 0.7090\n",
      "Accuracy during testing of fold  5  is : 0.6909\n",
      "\n",
      "Average accuracy is :  0.6936\n",
      "\n",
      "\n",
      "Execution time in seconds =  0:00:00.167880\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "from math import log\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "\n",
    "def mean(val):\n",
    "    return sum(val)/len(val)\n",
    "\n",
    "\n",
    "def class_stats(df,col,col_class):\n",
    "    \n",
    "    df_class = df[col_class]\n",
    "    possible_classes = dict()\n",
    "    l1 = []\n",
    "    for i in df_class:\n",
    "        l1.append(i)\n",
    "    l1 = set(l1)\n",
    "    \n",
    "    df_class_cal = dict()\n",
    "    \n",
    "    for class_val in l1:\n",
    "        df_class_cal[int(class_val)] = df.loc[df[col_class] == class_val]\n",
    "    \n",
    "    values = dict()\n",
    "    \n",
    "    for i in l1:\n",
    "        l = []\n",
    "        for j in col:\n",
    "            l.append(mean(df_class_cal[i][j]))\n",
    "        values[i] = l\n",
    "        \n",
    "    return values\n",
    "\n",
    "def prob(att_value,mean):\n",
    "    ld = 1/mean\n",
    "    val = att_value * ld\n",
    "    e = exp(-val)\n",
    "    return ld * e\n",
    "    \n",
    "\n",
    "def cal_row_prob_for_class(val,row,prior_prob):\n",
    "    probability = dict()\n",
    "    \n",
    "    for class_selected, class_att_values in val.items():\n",
    "        probability[class_selected] = log(prior_prob[class_selected])\n",
    "        \n",
    "        for i in range(len(class_att_values)):\n",
    "            mean = class_att_values[i]\n",
    "            probability[class_selected] += log(prob(row[i],mean))\n",
    "    \n",
    "    return probability\n",
    "\n",
    "def predict_class(val,row,prior_prob):\n",
    "    class_probs = cal_row_prob_for_class(val,row,prior_prob)\n",
    "\n",
    "    label = 0\n",
    "    cl_prob = 0\n",
    "    \n",
    "    for i in class_probs.keys():\n",
    "        if(class_probs[i] > cl_prob):\n",
    "            label = i\n",
    "            cl_prob = class_probs[i]\n",
    "            \n",
    "    return label\n",
    "\n",
    "def split_data(k_folds,df):\n",
    "    df_list =[]\n",
    "    count = int(len(df)/k_folds)\n",
    "    \n",
    "    for i in range(k_folds):\n",
    "        beg_index = i * count\n",
    "        end_index = (i+1) * count\n",
    "        if i == k_folds-1:\n",
    "            end_index = len(df)\n",
    "\n",
    "        df_list.append(df[beg_index:end_index])\n",
    "        \n",
    "    return df_list\n",
    "\n",
    "def accuracy(o,y):\n",
    "    count = 0\n",
    "    for i in range(len(o)):\n",
    "        if o[i] == y[i]:\n",
    "            count += 1\n",
    "            \n",
    "    return count/len(o)\n",
    "\n",
    "def naive_bayes(train_df,test_df,col,col_class,prior_prob):\n",
    "    \n",
    "    val = class_stats(train_df,col,col_class)\n",
    "    X_test = np.array(test_df[col])\n",
    "    y_test = np.array(test_df[col_class])\n",
    "    \n",
    "    o = []\n",
    "    \n",
    "    for i in X_test:\n",
    "        o.append(predict_class(val,i,prior_prob))\n",
    "        \n",
    "    return accuracy(o,y_test)\n",
    "\n",
    "def evaluate(df,k_folds,col,col_class,prior_prob):\n",
    "    \n",
    "    df_list = split_data(k_folds,df)\n",
    "    score = []\n",
    "    \n",
    "    for i in range(k_folds):\n",
    "        train_df = pd.DataFrame()\n",
    "        test_df = pd.DataFrame()\n",
    "        \n",
    "        for j in range(0,i):\n",
    "            train_df = pd.concat([train_df,df_list[j]], ignore_index=True)\n",
    "            \n",
    "        for j in range(i+1,k_folds):\n",
    "            train_df = pd.concat([train_df,df_list[j]], ignore_index=True)\n",
    "            \n",
    "        test_df = df_list[i]\n",
    "        \n",
    "        acc = naive_bayes(train_df,test_df,col,col_class,prior_prob)\n",
    "        score.append(acc)\n",
    "        \n",
    "    return score\n",
    "\n",
    "def normalize(x):\n",
    "    result = x.copy()\n",
    "    for feature_name in x.columns:\n",
    "        max_value = x[feature_name].max()\n",
    "        min_value = x[feature_name].min()\n",
    "        result[feature_name] = (x[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "df = pd.read_csv('ILPD.csv')\n",
    "df = normalize(df)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "prior_prob = dict()\n",
    "\n",
    "df_liver = df.loc[df['Selector'] == 0]\n",
    "df_noliver = df.loc[df['Selector'] == 1]\n",
    "\n",
    "prior_prob[0] = len(df_liver)/len(df)\n",
    "prior_prob[1] = len(df_noliver)/len(df)\n",
    "\n",
    "col = ['Age','Gender','TB','DB','Alkphos','Sgpt','Sgot','TP','ALB','A/G']\n",
    "col_class = 'Selector'\n",
    "\n",
    "score = evaluate(df,5,col,col_class,prior_prob)\n",
    "\n",
    "\n",
    "for i in range(len(score)):\n",
    "    print(\"Accuracy during testing of fold \",i+1,\" is :\",\"{:5.4f}\".format(score[i]))\n",
    "\n",
    "\n",
    "mean = sum(score)/len(score)\n",
    "\n",
    "print(\"\\n\" + \"Average accuracy is : \",\"{:5.4f}\".format(mean))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Execution time in seconds = \", datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
